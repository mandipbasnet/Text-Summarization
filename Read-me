Text Summarizer using NLTK

Introduction

This project is a simple text summarizer built with Python, leveraging Natural Language Processing (NLP) techniques. It uses NLTK (Natural Language Toolkit) to process and analyze text, extracting the most relevant sentences to generate concise summaries.

Prerequisites

Ensure you have Python installed along with the following dependencies:

NLTK (Natural Language Toolkit)

re (Regular Expressions — built-in)

heapq (Heap Queue Algorithm — built-in)

Install NLTK with:

pip install nltk

Project Structure

text_summarizer.py: Contains the code for the text summarization.

How It Works

Text Cleaning:

Removes unnecessary spaces to ensure proper text processing.

Tokenization:

Splits the input text into sentences and words.

Stop Words Removal:

Filters out common stop words (e.g., "is," "the," "and") to focus on meaningful words.

Word Frequency Calculation:

Counts the occurrence of each word in the text, ignoring stop words.

Sentence Scoring:

Scores each sentence based on the frequency of the words it contains.

Summary Extraction:

Selects the top-scoring sentences and combines them to form the summary.

Code Explanation

import nltk
import heapq
import re
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize, sent_tokenize

# Download necessary datasets
nltk.download('punkt')
nltk.download('stopwords')

# Function to summarize text
def summarize_text(text, summary_length=3):
    # Step 1: Clean the text
    text = re.sub(r'\s+', ' ', text)
    
    # Step 2: Tokenize sentences and words
    sentences = sent_tokenize(text)
    words = word_tokenize(text.lower())
    stop_words = set(stopwords.words('english'))
    
    # Step 3: Calculate word frequencies
    word_frequencies = {}
    for word in words:
        if word not in stop_words and word.isalpha():
            word_frequencies[word] = word_frequencies.get(word, 0) + 1
    
    # Step 4: Score sentences
    sentence_scores = {}
    for sentence in sentences:
        for word in word_tokenize(sentence.lower()):
            if word in word_frequencies:
                sentence_scores[sentence] = sentence_scores.get(sentence, 0) + word_frequencies[word]
    
    # Step 5: Extract top sentences
    summary_sentences = heapq.nlargest(summary_length, sentence_scores, key=sentence_scores.get)
    summary = ' '.join(summary_sentences)
    return summary

Emple Usage

if __name__ == "__main__":
    text = """Natural Language Processing (NLP) is a field of artificial intelligence that gives machines the ability to read, understand, and derive meaning from human languages. It is used to apply algorithms to identify and extract the natural language rules such that the unstructured language data is converted into a form that machines can understand. The process involves parsing text into its basic components, such as words and sentences, understanding grammar, and interpreting meaning. NLP has numerous applications, including chatbots, machine translation, sentiment analysis, and summarization."""

    print("Original Text:\n", text)
    print("\nSummarized Text:\n", summarize_text(text))

Output Example

Original Text:
Natural Language Processing (NLP) is a field of artificial intelligence that gives machines the ability to read, understand, and derive meaning from human languages. It is used to apply algorithms to identify and extract the natural language rules such that the unstructured language data is converted into a form that machines can understand. The process involves parsing text into its basic components, such as words and sentences, understanding grammar, and interpreting meaning. NLP has numerous applications, including chatbots, machine translation, sentiment analysis, and summarization.

Summarized Text:
Natural Language Processing (NLP) is a field of artificial intelligence that gives machines the ability to read, understand, and derive meaning from human languages. NLP has numerous applications, including chatbots, machine translation, sentiment analysis, and summarization.

Conclusion

This project demonstrates a simple yet effective approach to text summarization using NLTK. It highlights fundamental NLP techniques like tokenization, stop word removal, and sentence scoring.

